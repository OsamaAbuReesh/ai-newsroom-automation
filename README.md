# ğŸª„ Arabic Editorial AI System â€” Streamlit + n8n Integration

## ğŸ“– Overview

This project integrates **Streamlit** with **n8n** to build an **Arabic Editorial AI System**  
that rewrites Arabic news according to three editorial policies:
- ğŸ“ **Najah Media** (Academic and Objective)
- ğŸ‡µğŸ‡¸ **Gaza TV** (National and Emotional)
- ğŸ—ï¸ **Najah News** (Journalistic and Direct)

The system allows users to:
1. Input Arabic text in Streamlit.
2. Select a preferred editorial policy.
3. Send the text to n8n via a webhook.
4. Process it through an AI model (LLM) that returns a structured JSON response.
5. Display both **original** and **edited** text in a clean, bilingual, and professional UI.

---

## ğŸ§© Workflow Name in n8n

**Workflow Name:** `Arabic Editorial AI System`

### ğŸ”— Workflow Structure:
**Webhook** (POST/webhook/edit-article) => **Function** (Generate Editorial Prompt) => **Baisc LLM Chain** (OpenAI Chat Model) => Respond To Webhook 


ğŸ“¸ **Workflow Screenshot**  
![Workflow Screenshot](n8n_workflow/screenshots/workflow_structure.png)

---

## ğŸ–¥ï¸ Streamlit Frontend

The Streamlit app provides an elegant Arabic-first interface that allows users to:
- Write or paste Arabic text.  
- Choose an editorial policy using interactive buttons.  
- Send the text to n8n and view both **Original** and **Edited** versions side-by-side.  
- View structured output sections (Ø§Ù„Ø¹Ù†ÙˆØ§Ù† , Ø§Ù„Ù…Ù‚Ø¯Ù…Ø© , Ø§Ù„ØªÙØ§ØµÙŠÙ„ , Ø§Ù„Ø®Ø§ØªÙ…Ø© , Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©) in color-coded cards.

ğŸ“¸ **Streamlit UI Example**  
![Streamlit UI](n8n_workflow/screenshots/streamlit_ui.png)

---
### ğŸ§  LLM Output Sample

This image shows an example of the **modelâ€™s structured JSON output**,  
generated by the **Basic LLM Chain** node after processing an Arabic news text.  
It demonstrates how the system returns all six key fields in Arabic format:

```json
{
  "Ø§Ù„ØªØµÙ†ÙŠÙ": "Ø®Ø¨Ø± Ù…Ø­Ù„ÙŠ",
  "Ø§Ù„Ø¹Ù†ÙˆØ§Ù†": "ÙˆØ²Ø§Ø±Ø© Ø§Ù„ØµØ­Ø© ØªØ·Ù„Ù‚ Ø­Ù…Ù„Ø© Ù„ØªØ·Ø¹ÙŠÙ… Ø§Ù„Ø£Ø·ÙØ§Ù„ Ø¶Ø¯ Ø§Ù„Ø¯ÙØªÙŠØ±ÙŠØ§",
  "Ø§Ù„Ù…Ù‚Ø¯Ù…Ø©": "Ø£Ø¹Ù„Ù†Øª ÙˆØ²Ø§Ø±Ø© Ø§Ù„ØµØ­Ø© Ø§Ù„ÙÙ„Ø³Ø·ÙŠÙ†ÙŠØ© Ø§Ù„ÙŠÙˆÙ… Ø¨Ø¯Ø¡ Ø­Ù…Ù„Ø© ÙˆØ·Ù†ÙŠØ© Ù„ØªØ·Ø¹ÙŠÙ… Ø§Ù„Ø£Ø·ÙØ§Ù„ Ø¶Ø¯ Ù…Ø±Ø¶ Ø§Ù„Ø¯ÙØªÙŠØ±ÙŠØ§...",
  "Ø§Ù„ØªÙØ§ØµÙŠÙ„": "ØªÙ‡Ø¯Ù Ø§Ù„Ø­Ù…Ù„Ø© Ø¥Ù„Ù‰ ØªØ¹Ø²ÙŠØ² Ø§Ù„Ù…Ù†Ø§Ø¹Ø© Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ù„Ø£Ø·ÙØ§Ù„ Ø¶Ù…Ù† Ø§Ù„Ø¨Ø±ÙˆØªÙˆÙƒÙˆÙ„ Ø§Ù„ØµØ­ÙŠ Ø§Ù„ÙÙ„Ø³Ø·ÙŠÙ†ÙŠ...",
  "Ø§Ù„Ø®Ø§ØªÙ…Ø©": "Ø¯Ø¹Øª Ø§Ù„ÙˆØ²Ø§Ø±Ø© Ø§Ù„Ø£Ù‡Ø§Ù„ÙŠ Ø¥Ù„Ù‰ Ù…Ø±Ø§Ø¬Ø¹Ø© Ø£Ù‚Ø±Ø¨ Ù…Ø±ÙƒØ² ØµØ­ÙŠ Ù„Ø§Ø³ØªÙƒÙ…Ø§Ù„ Ø§Ù„Ø¬Ø±Ø¹Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©.",
  "Ø§Ù„ÙƒÙ„Ù…Ø§Øª_Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©": ["Ø§Ù„ØµØ­Ø©", "ØªØ·Ø¹ÙŠÙ…", "Ø§Ù„Ø£Ø·ÙØ§Ù„", "ÙÙ„Ø³Ø·ÙŠÙ†"]
}

```

![LLM Output Sample](n8n_workflow/screenshots/llm_output_sample.png)

## ğŸ§  AI Model Configuration

| Parameter | Value |
|------------|--------|
| **Model** | `gpt-4o-mini` |
| **Provider** | OpenAI Chat Model |
| **Temperature** | 0.7 |
| **Output Parser** | Structured JSON Parser (enabled) |

**JSON Output Schema**
{
  "Ø§Ù„ØªØµÙ†ÙŠÙ": "",
  "Ø§Ù„Ø¹Ù†ÙˆØ§Ù†": "",
  "Ø§Ù„Ù…Ù‚Ø¯Ù…Ø©": "",
  "Ø§Ù„ØªÙØ§ØµÙŠÙ„": "",
  "Ø§Ù„Ø®Ø§ØªÙ…Ø©": "",
  "Ø§Ù„ÙƒÙ„Ù…Ø§Øª_Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©": []
}
